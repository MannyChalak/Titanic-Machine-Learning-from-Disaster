# Titanic - Machine Learning from Disaster

This repository contains a project for predicting passenger survival on the Titanic using machine learning techniques. It is part of a Kaggle competition where participants analyze Titanic passenger data to build a predictive model for survival outcomes. This project uses Python for data analysis, feature engineering, and model building.

## Table of Contents
- [Project Overview](#project-overview)
- [Dataset](#dataset)
- [Installation](#installation)
- [Methodology](#methodology)
- [Results](#results)

## Project Overview
The main objective of this project is to predict whether a passenger survived the Titanic disaster based on a variety of features like age, gender, and socio-economic class. This project serves as a practical introduction to data science and machine learning techniques, covering steps like data preprocessing, exploratory data analysis, feature engineering, model selection, and evaluation.

## Dataset
The dataset is sourced from [Kaggle's Titanic competition](https://www.kaggle.com/c/titanic). It consists of two files:
- **train.csv** - The training dataset with survival outcomes.
- **test.csv** - The testing dataset without survival outcomes (for model predictions).

## Installation
1. Clone this repository:
   ```bash
   git clone https://github.com/MannyChalak/Titanic-Machine-Learning-from-Disaster.git
   cd Titanic-Machine-Learning-from-Disaster

## Methodology
The project is divided into several key steps:
1. Data Cleaning - Handling missing values, data transformations, and removing outliers.
2. Exploratory Data Analysis (EDA) - Visualizing data distributions and relationships.
3. Exploratory Data Analysis (EDA) - Visualizing data distributions and relationships.
4. Model Building - Implementing various machine learning models, such as logistic regression, random forest, and gradient boosting.
5. Model Evaluation - Evaluating model performance using metrics like accuracy, precision, and recall.

## Results
This project has yielded a predictive model with an accuracy score of approximately ~75% on the test dataset.

